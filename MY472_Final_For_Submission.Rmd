---
title: "MY472_Final"
author: "CT-Dev1"
date: "01/01/2024"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r load_packages, eval = TRUE}
#Load required packages
library(ukpolice)
library(tidyverse)
library(sf)
library(sp)
library(httr)
library(jsonlite)
library(RSQLite)
library(httr)
library(netstat)
library(texreg)
library(gt)
library(viridis)
library(gtsummary)
```

```{r load_data, eval = TRUE, message = FALSE}
#Ethnicity Population Data by LSOAs (downloaded from office for national statistics - 2021 data)
ethnicity_data <- read.csv("data\\LSOA_ethnicity.csv")

#Local District Shape Files from GeoJSON
LSOA_shapes <- st_read("data\\LSOA_shapefiles.geojson") %>% 
  rename(LSOA_code = LSOA21CD, LSOA_name = LSOA21NM)
  
#Sex and Age Population Data For England and Wales
pop_by_sex_age <- read.csv("data\\pop_by_sex_age.csv")

#Police Force Shape files from GeoJSON
pf_shapes <- st_read("data\\force_areas_shapefiles.geojson") %>% 
  rename(force_name = pfa16nm, force_code = pfa16cd) %>% 
  mutate(force_name = ifelse(force_name=="Metropolitan Police", "Metropolitan", force_name))
```

```{r process_data, eval = TRUE}
#Create table for LSOAs by police force area
LSOA_by_force <- LSOA_shapes %>% 
  st_centroid() %>% 
  st_join(pf_shapes, join = st_intersects) %>% 
  as_tibble() %>% 
  select("LSOA_code", "LSOA_name", force_code, force_name)

#Create table for population by ethnicity for LSOA
ethnicity_by_LSOA <- ethnicity_data %>% 
  rename(LSOA_code = Lower.layer.Super.Output.Areas.Code, LSOA_name = Lower.layer.Super.Output.Areas, ethnic_group = Ethnic.group..20.categories.) %>%
  select(LSOA_code, Observation, ethnic_group) %>%
  pivot_wider(names_from = ethnic_group, values_from = Observation) %>% 
  mutate(total_pop = rowSums(across(where(is.numeric))))

#Read in the MSOA shapefiles
MSOA_shapes <- st_read("data//MSOA_shapefiles.geojson") %>% 
  rename(MSOA_code = MSOA21CD, MSOA_name = MSOA21NM) %>% 
  st_join(pf_shapes, join = st_intersects) %>% 
  filter(force_name == "Metropolitan") %>% 
  st_transform(crs = 4326)

#Joining the two tables
ethnicity_by_force <- LSOA_by_force %>% 
  full_join(ethnicity_by_LSOA, by = "LSOA_code") %>% 
  group_by(force_code, force_name) %>%
  mutate(force_name = str_replace_all(force_name, " Police", "")) %>%
  summarize(across(where(is.numeric), sum, na.rm = TRUE))

#Cleaning the age and sex population data
pop_by_sex_age <- pop_by_sex_age %>% 
  select(Sex..2.categories., Age..91.categories..Code, Observation) %>% 
  rename(gender = Sex..2.categories., age = Age..91.categories..Code, population = Observation) %>% 
  mutate(population_percent = (population/sum(population))*100)
```

```{r API_input_dataset, eval = TRUE}
#Create table that relates API input, force name and force code in standard format
police_forces <- ukc_forces()%>% 
  rename(force_name = name, ukc_input = id)%>% 
  mutate(force_name = str_replace_all(force_name, " Police", "")) %>% 
  mutate(force_name = str_replace_all(force_name, " Constabulary", "")) %>% 
  mutate(force_name = str_replace_all(force_name, "&", "and")) %>%
  mutate(force_name = str_replace_all(force_name, " Service", "")) %>%
  inner_join(ethnicity_by_force, by = "force_name") %>% 
  select(force_name, ukc_input, force_code)

#Vector of months to loop through, input into API
dates <- c("2022-01","2022-02","2022-03","2022-04","2022-05","2022-06","2022-07","2022-08","2022-09","2022-10","2022-11","2022-12")
```


```{r API_query_loop, eval = FALSE}
'
#Function to clean the raw data from API
clean_ss_data <- function(ss_data, force, month) {
  force_data <- ss_data %>% 
    mutate(ukc_input = force) %>% 
    inner_join(police_forces, by = "ukc_input") %>% 
    select(age_range, gender, self_defined_ethnicity, officer_defined_ethnicity, legislation, object_of_search, outcome_object_name, legislation, force_code, force_name, ukc_input) %>% 
    #replace "Not stated" ethnicity with NA
    mutate(self_defined_ethnicity = ifelse(grepl("Not stated", self_defined_ethnicity), NA, self_defined_ethnicity)) %>% 
    mutate(racial_group = ifelse(is.na(self_defined_ethnicity), officer_defined_ethnicity, self_defined_ethnicity)) %>% 
    #Add column for racial_group based on ethnicity classification
    mutate(racial_group = ifelse(grepl("Mixed", racial_group, fixed = TRUE), 'Mixed',
                           ifelse(grepl("Asian", racial_group, fixed = TRUE), 'Asian',
                           ifelse(grepl("Black", racial_group, fixed = TRUE), 'Black',
                           ifelse(grepl("White", racial_group, fixed = TRUE), 'White',
                           ifelse(grepl("Other", racial_group, fixed = TRUE), 'Other', NA)))))) %>% 
    mutate(month = month)
  return(force_data)
}

#Script to download stop and search data for all police forces over 2022

#Empty tibble to store the data
stop_search_2022 <- ukc_stop_search_force("bedfordshire","2022-01") %>%
  clean_ss_data("bedfordshire", "2022-01") %>%
  slice(0)

#table to store missing forces and months
missing_data = tibble(ukc_input = character(), month = character())

#Loop over all police forces and months
for (month in dates){
  for (force in police_forces$ukc_input){
    force_data <- ukc_stop_search_force(force, month)
    if (length(force_data)==0 | is.null(force_data)){
      missing_data <- missing_data %>% 
        add_row(ukc_input = force, month = month)
      next
    } else {
    stop_search_2022 <- force_data %>% 
      clean_ss_data(force, month) %>%
      rbind(stop_search_2022)
    }}
  Sys.sleep(3) 
}
'
```


```{r API_forward_filling_for_missing_data, eval = FALSE}
#There is missing data, so investigate police API issue log at https://data.police.uk/changelog/
#Some forces have partial missing data for 2022, so we will utilize forward propagation to fill in the data
'
#Create table of partial missing data
partial_missing_forces <- missing_data %>% 
  filter(ukc_input %in% c("greater-manchester","gwent", "north-yorkshire")==FALSE) %>% 
  mutate(month_index = as.numeric(str_replace_all(month, "2022-", ""))) 

#create table of inputs for forward propagation
forward_prop_input <- missing_data %>% 
  filter(ukc_input %in% c("greater-manchester","gwent", "north-yorkshire")==FALSE) %>% 
  group_by(ukc_input) %>%
  summarize(missing_months = n()) %>% 
  inner_join(police_forces, by = "ukc_input")

#Script to loop over missing data by force and month

for (force in forward_prop_input$ukc_input){
  missing_months <- forward_prop_input$missing_months[forward_prop_input$ukc_input==force]
  last_record_month <- min(partial_missing_forces$month_index[partial_missing_forces$ukc_input==force]) -1
  month_input <- paste0("2022-", last_record_month)
  for (i in 1:forward_prop_input$missing_months[forward_prop_input$ukc_input==force]){
    force_data <- ukc_stop_search_force(force, month_input)
    month_filled_input <- paste0("2022-", last_record_month+i)
    stop_search_2022 <- force_data %>% 
      clean_ss_data(force, month_filled_input) %>%
      rbind(stop_search_2022)
  }
}
'
#Write to disk, this is commented out, data is stored in stop_search_2022.csv in data folder (within the github)
#write.csv(stop_search_2022, "data//stop_search_2022.csv", row.names=FALSE)
```


```{r load_pre_scraped_data, eval = TRUE}
#Load full dataset from csv, which is only missing data for Greater Manchester, Gwent and North Yorkshire, these I add manually at later stages
stop_search_2022 <- read_csv("data//stop_search_2022.csv")
```

```{r test_for_data_completeness, eval = FALSE}
#test that forward propagation worked using the test case of South Wales, which previously had some missing data
'
stop_search_2022 %>% 
  filter(force_name == "South Wales") %>% 
  group_by(month) %>% 
  summarize(total_stops = n()) %>% 
  print()

#Demonstration that API fails for some forces - greater manchester, gwent and north yorkshire
url <- "https://data.police.uk/api/stops-force?force=greater-manchester&date=2022-02"
json <- content(GET(url), "parsed")
print(is.null(json)|length(json)==0)
'
```

```{r sex_and_age_data_analysis}
#format the sex and age population stats to match the format in police.uk data
pop_sex_age_formatted <- pop_by_sex_age %>% 
  mutate(age_range = ifelse(age < 10, "under 10", 
                    ifelse(age <=17, "10-17", 
                     ifelse(age <=24, "18-24",
                    ifelse(age <= 34, "25-34", "over 34"))))) %>% 
  group_by(age_range, gender) %>%
  summarize(population = sum(population), population_percent=sum(population_percent))
  
#Stop rates by sex and age
stops_by_age_and_sex <- stop_search_2022 %>% 
  filter(is.na(age_range)==FALSE) %>% 
  group_by(age_range, gender) %>%
  summarize(stops_recorded = n()) %>% 
  filter(gender %in% c("Male", "Female")) %>% 
  #total stops is 426768 (stops with recorded age_range data)
  mutate(percentage_stops = (stops_recorded/426768)*100) %>% 
  inner_join(pop_sex_age_formatted, by = join_by(age_range, gender))

age_gender_percent_stops <- stops_by_age_and_sex %>% 
  select(age_range, gender, percentage_stops) %>% 
  mutate(gender = paste0("stops-", gender)) %>% 
  rename(percentage = percentage_stops)

age_sex_stops_population <- stops_by_age_and_sex %>% 
  select(age_range, gender, population_percent) %>% 
  mutate(population_percent = -1*population_percent) %>% 
  mutate(gender = paste0("population-", gender)) %>% 
  rename(percentage = population_percent) %>% 
  rbind(age_gender_percent_stops) %>% 
  filter(age_range != "under 10")

stops_by_age_and_sex_histogram <- age_sex_stops_population %>% 
  ggplot(aes(x = age_range, y = percentage, fill = gender)) +
  geom_bar(stat = "identity", position = "stack", width = 0.50) +
  scale_y_continuous(breaks = seq(-60, 60, by = 10), labels = abs(seq(-60,60,by=10)), limits = c(-60,60)) +
  geom_hline(yintercept = 0, linetype = "solid", color = "black", size = 1) +
  coord_flip() +
  scale_fill_manual(values = c("population-Female" = "skyblue", "stops-Female" = "skyblue", "population-Male" = "skyblue4", "stops-Male" = "skyblue4"),
                      breaks = c("population-Female", "population-Male"),
                      labels = c("Female", "Male")) + 
  theme(aspect.ratio = 3/9, axis.text.y = element_text(angle = 0, hjust = 1)) +
  ylab("Percent") +
  xlab("Age Group") +
  ggtitle(str_wrap("Proportion of stop and search by age and sex of person compared with the population", width=80), "England and Wales | 2022 | Based on 426,768 total searches") +
  annotate("text", x = 1, y = 50, label = "Proportion of Stop\nand Search in each \nage group", vjust = -1, size = 3) +
  annotate("text", x = 1, y = -30, label = "Proportion of \nPopulation in each \nage group", vjust = -1, size = 3) +
  labs(fill = "Sex")
  
stops_by_age_and_sex_histogram
```


```{r racial_analysis_data_for_missing_forces, eval = TRUE}
#Manchester, Gwent and North Yorkshire have no data at all
#Rather than exclude from analysis, we can load in existing racial search data from gov.uk
missing_forces_ss <- read.csv("data/missing_forces_stop_search.csv")
missing_forces_ss <- missing_forces_ss %>% 
  rename(number_of_stop_and_searches_ethnicity_reported = total_number_of_stop_and_search_carried_out_in_this_year_in_this_area_excluding_cases_where_the_ethnicity_was_unreported, stop_search_rate_ethnicity = proportion_of_total_stop_and_searches_of_this_ethnicity_in_the_financial_year_excludes_unreported, force_name = geography) %>%
  mutate(time = as.character(time)) %>% 
  filter(force_name %in% c("Gwent", "Greater Manchester", "North Yorkshire")==TRUE) %>% 
  filter(geography_type == "Police Force Area" & time == "2021/22") %>% 
  #Note ethnicity column is coded differently in this dataset, includes labels for ethnicity and race
  select(ethnicity, force_name, number_of_stop_and_searches, number_of_stop_and_searches_ethnicity_reported, population_by_ethnicity, rate_per_1_000_population_by_ethnicity, stop_search_rate_ethnicity)

#Now we can combine these datasets to have a complete picture across all force areas

```

Notes on missing data source:
- Is for financial year 2021-22, so not exactly calendar year but a good approximation

```{r racial_analysis_dataset_complete, eval = TRUE}
#Begin by analyzing race

#To find search rate per 1000, first we need populations by force area
race_by_force <- ethnicity_by_force %>% 
  pivot_longer(cols = -c(force_code,force_name), names_to = "racial_group", values_to = "population") %>% 
  mutate(racial_group = ifelse(grepl("White", racial_group, fixed = TRUE), 'White',
                       ifelse(grepl("Asian", racial_group, fixed = TRUE), 'Asian',
                       ifelse(grepl("Black", racial_group, fixed = TRUE), 'Black',
                       ifelse(grepl("Mixed", racial_group, fixed = TRUE), 'Mixed',
                       ifelse(grepl("Other", racial_group, fixed = TRUE), 'Other', NA)))))) %>%
  group_by(force_name, racial_group) %>% 
  summarize(population = sum(population[racial_group==racial_group])) %>% 
  filter(is.na(racial_group)==FALSE) %>%
  pivot_wider(names_from = racial_group, values_from = "population", names_prefix = "population_") %>% 
  mutate(population_Total = population_White + population_Black + population_Mixed + population_Asian + population_Other) %>%
  inner_join(police_forces, by = "force_name")

#First let's find the number of stops by race for the three missing forces (Manchester, Gwent and North Yorkshire)
race_stops_data_missing <- missing_forces_ss %>% 
  filter(ethnicity %in% c("White", "Black", "Mixed", "Asian", "Other")==TRUE) %>% 
  select(c(number_of_stop_and_searches, ethnicity, force_name)) %>% 
  pivot_wider(names_from = ethnicity, values_from = number_of_stop_and_searches, names_prefix = "stops_")

#Next lets find the total searches by force area, including those with no racial data
stops_total_by_force <- stop_search_2022 %>% 
  group_by(force_name) %>% 
  summarize(number_of_stop_and_searches = n()) %>% 
  inner_join(police_forces, by = "force_name") %>% 
  bind_rows(missing_forces_ss) %>% 
  #get first 43 rows
  slice(1:43) %>%
  select(force_name, number_of_stop_and_searches) %>%
  rename(stops_Total = number_of_stop_and_searches)

#Finally, lets aggregate all tables, finding racial stop rates for each force - FINAL RACIAL DATA
race_stops_data <- stop_search_2022 %>% 
  #Filter for stops where racial group is known
  filter(is.na(racial_group)==FALSE) %>% 
  group_by(force_name) %>% 
  summarize(stops_Black = sum(racial_group=="Black"), stops_White = sum(racial_group=="White"), stops_Mixed = sum(racial_group=="Mixed"), stops_Asian = sum(racial_group=="Asian"), stops_Other = sum(racial_group=="Other")) %>% 
  #Add the missing forces
  rbind(race_stops_data_missing) %>%
  mutate(stops_All = stops_Black + stops_White + stops_Mixed + stops_Asian + stops_Other) %>%
  inner_join(police_forces, by = "force_name") %>%
  inner_join(race_by_force, by = c("force_name","force_code","ukc_input")) %>%
  #Find rates of stop and search per 1000 people
  inner_join(stops_total_by_force, by = "force_name") %>% 
  mutate(stop_rate_black = (stops_Black/population_Black)*1000, stop_rate_white = (stops_White/population_White)*1000, stop_rate_mixed = (stops_Mixed/population_Mixed)*1000, stop_rate_asian = (stops_Asian/population_Asian)*1000, stop_rate_other = (stops_Other/population_Other)*1000, stop_rate_all_races = (stops_All/population_Total)*1000, stops_rate_Total = (stops_Total/population_Total)*1000) 
```


```{r map_total_search_rate_by_force, eval=TRUE}
#cities points to add to maps
uk_cities <- read.csv("data//gb_cities.csv") %>% 
  st_as_sf(coords = c("lng", "lat"), crs = 4326) %>% 
  st_transform(27700) %>% 
  filter(population > 500000)

#We can visualize the above table on a map to get a better sense of geographic variation
total_stop_rate_map <- pf_shapes %>% 
  inner_join(race_stops_data, by = c("force_name")) %>%
  select(force_name, stops_rate_Total) %>%
  #Filter out city of london as outlier
  filter(force_name != "City of London") %>%
  ggplot() + geom_sf(aes(fill = stops_rate_Total)) +
  scale_fill_viridis_c( 
                       direction = -1, 
                       na.value = "grey90", 
                       name = str_wrap("Total searches per 1000 Population", width = 15), 
                       trans = "identity") +
  theme_void() +
  theme(legend.position = "right") +
  labs(title = "Search Rate by Police Force Area", subtitle = "2022", caption = "Source: police.uk | Based on 507,381 Total Searches") +
  geom_sf(data = uk_cities, color = "red2", size = 2.6) +
  annotate("text", x = 180050.1, y = 480358.4, label = str_wrap("Dots Represent Cities with Population > 500,000",width=20), size = 3)

total_stop_rate_map
```
-Exclude city of london from further estimates
```{r bar_plot_search_rate_by_PFA, eval=TRUE}
#Displaying via histogram
ss_rate_by_force <- race_stops_data %>% 
  filter(force_name != "City of London") %>% 
  select(force_name, stops_rate_Total) %>% 
  mutate(stop_rate_total = stops_rate_Total) %>% 
  arrange(desc(stop_rate_total))

#Order forces in descending order by stop rate
ss_rate_by_force$force_name <- factor(ss_rate_by_force$force_name, levels = ss_rate_by_force$force_name[order(-ss_rate_by_force$stop_rate_total)])

#Generate Bar plot
total_stop_rate_histogram <- ggplot(ss_rate_by_force, aes(x = force_name, y = stop_rate_total)) +
  geom_bar(stat = "identity", color = "black", fill = "lightblue", width = 0.8) + # Increase bar spacing by reducing width
  scale_y_continuous(expand = c(0,0), limits = c(0, 50), breaks = seq(0, 50, by = 10)) + # Set y-axis limits and breaks
  theme_minimal(base_size = 10) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 6), # Rotate and adjust the font size
        axis.title = element_text(size = 12), # Adjust the axis title font size if needed
        panel.grid.major = element_line(color = "gray", size = 0.5), # Add major grid lines
        panel.grid.minor = element_blank(), # Disable minor grid lines
        panel.background = element_rect(fill = "white"),axis.line = element_line(color = "black")) +  # Add axis lines
  labs(title = "Stop Search Rate by Police Force Area",
       subtitle = "England and Wales, 2022",
       x = "Police Force Area (PFA)",
       y = "Searches per 1000 Residents")

total_stop_rate_histogram
```



```{r table_of_search_rate_by_race_PFA, eval=TRUE}
#Now we can visualize the racial search data

#Summary table - race stop rates by force
race_stops_data %>% 
  select(force_name, stop_rate_black, stop_rate_white, stop_rate_mixed, stop_rate_asian, stop_rate_other, stop_rate_all_races, stops_rate_Total) %>%
  rename("Police Force" = force_name, Black = stop_rate_black, White = stop_rate_white, Mixed = stop_rate_mixed, Asian = stop_rate_asian, Other = stop_rate_other, "All Races*" = stop_rate_all_races, "Total Stops**" = stops_rate_Total) %>%
  gt() %>% 
  fmt_number(columns = c(everything()), decimals = 2) %>%
  tab_header(title = md("**Rates of Stop and Search by Racial Group and Police Force Area**")) %>% tab_spanner(label = md("**Rate per 1000 Residents in 2022**"), columns = c(2:8)) %>% 
  opt_row_striping() %>% 
  tab_footnote(
    footnote = "
    *'All Races' is the rate for all stops where racial data is recorded | **'Total stops' is the rate for all stops recorded"
  ) %>% 
  tab_style(
    style = list(cell_text(weight = "bold")),
    locations = list(cells_column_labels(columns = everything()), cells_body(columns = c(1))))
```
Notes on table above:
- Demonstrates stop and search rate varies significantly across areas
- Gives the outlier of City of London - it should be removed from further analysis
- Note that all races stop rate may be smaller than official statistics given that we are analysing on searches where race is known
- add column for demographic - number of total searches and population


```{r map_racial_disparity_rate, eval=TRUE}
library(viridis)
black_stop_rate_map <- pf_shapes %>% 
  inner_join(race_stops_data, by = c("force_name")) %>%
  select(force_name, stop_rate_black, stop_rate_white) %>% 
  mutate(black_white_ratio = stop_rate_black/stop_rate_white) %>%
  #limit range of ratio to 5
  mutate(black_white_ratio = ifelse(black_white_ratio > 8, 8, black_white_ratio)) %>%
  filter(force_name != "City of London") %>%
  ggplot() + 
  geom_sf(aes(fill = black_white_ratio)) +
  scale_fill_viridis_c(
    direction = -1, 
    na.value = "red", 
    name = str_wrap("Search Disparity Rate: Black vs. White", width=15),
    trans = "identity",
    limits = c(0, 8),
    breaks = c(0, 2, 4, 6, 8),
    labels = c("0", "2", "4", "6", "8+")
  ) +
  theme_void() +
  theme(legend.position = "right") +
  labs(title = str_wrap("Search Disparity Rate by Force Area: Black vs. White Racial Group", width = 35), subtitle = "2022", caption = "Source: police.uk | Based on 485,930 Searches") +
  geom_sf(data = uk_cities, color = "red2", size = 2.6) +
  annotate("text", x = 180050.1, y = 480358.4, label = str_wrap("Dots Represent Cities with Population > 500,000",width=20), size = 3)
black_stop_rate_map
```

```{r}
#Barplot of the disparity rate by force area

#Order forces in descending order by stop rate
race_stops_data$force_name <- factor(race_stops_data$force_name, levels = race_stops_data$force_name[order(-race_stops_data$stop_rate_black)])

race_stops_data <- race_stops_data %>% 
  filter(force_name != "City of London")

#Generate Bar plot
black_stop_rate_histogram <- race_stops_data %>% 
  filter(force_name != "City of London") %>% 
  select(force_name, stop_rate_black, stop_rate_white) %>%
  pivot_longer(cols = c(stop_rate_black,stop_rate_white), names_to = "race", values_to = "stop_rate") %>% 
  ggplot(aes(x = force_name, y = stop_rate, fill = race)) +
  geom_bar(stat = "identity", position = "identity", alpha = 0.5, width = 0.8) + 
  scale_y_continuous(expand = c(0,0), limits = c(0, 120), breaks = seq(0, 120, by = 10)) +
  theme_minimal(base_size = 10) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 6), # Rotate and adjust the font size
        axis.title = element_text(size = 12), # Adjust the axis title font size if needed
        panel.grid.major = element_line(color = "gray", size = 0.5), # Add major grid lines
        panel.grid.minor = element_blank(), # Disable minor grid lines
        panel.background = element_rect(fill = "white"),
        axis.line = element_line(color = "black"), legend.position = "bottom") +  # Add axis lines
  labs(title = "Stop Search Rate by Police Force Area",
       subtitle = "England and Wales, 2022",
       x = "Police Force Area (PFA)",
       y = "Searches per 1000 Residents",
       fill = "Racial Group") +  
  scale_fill_manual(values = c("stop_rate_black" = "skyblue", "stop_rate_white" = "gray10"),
                     labels = c("Black Ethnicity", "White Ethnicity"))
black_stop_rate_histogram
```

```{r}
#LONDON CASE STUDY DATASET

#Ensure spherical data use set to false otherwise, this chunk will error
sf_use_s2(FALSE)

#Finding BAME population per MSOA
MSOA_BAME_pop <- MSOA_shapes %>% 
  st_transform(crs = 27700) %>%
  st_join(LSOA_shapes, join = st_intersects) %>% 
  as_tibble() %>% 
  select(MSOA_code, LSOA_code) %>% 
  inner_join(ethnicity_by_LSOA, by = c("LSOA_code")) %>%
  select(-c("Does not apply", total_pop)) %>%
  pivot_longer(cols = -c(MSOA_code,LSOA_code), names_to = "ethnicity", values_to = "population") %>% 
    mutate(racial_group = ifelse(grepl("Mixed", ethnicity, fixed = TRUE), 'Mixed',
                           ifelse(grepl("Asian", ethnicity, fixed = TRUE), 'Asian',
                           ifelse(grepl("Black", ethnicity, fixed = TRUE), 'Black',
                           ifelse(grepl("White", ethnicity, fixed = TRUE), 'White',
                           ifelse(grepl("Other", ethnicity, fixed = TRUE), 'Other', NA)))))) %>% 
  mutate(BAME = ifelse(racial_group == "White", "White", "BAME")) %>% 
  group_by(MSOA_code, BAME) %>%
  summarise(population = sum(population)) %>%
  pivot_wider(names_from = BAME, values_from = population) %>%
  mutate(Total = White + BAME) %>%
  mutate(BAME_prop = (BAME/Total)*100, White_prop=(White/Total)*100)


#Finding the total number of searches per MSOA in Metropolitan police force area
metro_data <- ukc_stop_search_force("metropolitan","2022-06") %>% as_tibble()

metro_search_data <- metro_data %>% 
  filter(!is.na(latitude)) %>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) %>% 
  st_join(MSOA_shapes) %>%
  filter(!is.na(MSOA_code)) %>%
  group_by(MSOA_code) %>%
  summarise(total_searches = n())
  
metro_search_map <- MSOA_shapes %>%
  st_join(metro_search_data, by = c("MSOA_code")) %>%
  mutate(total_searches = ifelse(is.na(total_searches), 0, total_searches)) %>% 
  mutate(total_searches = ifelse(total_searches > 150, 150, total_searches)) %>% 
  ggplot() +
  geom_sf(aes(fill = total_searches), alpha = 0.6) +
  scale_fill_viridis_c(name = "Total Searches",  
                       labels = c("0","50","100", "150+")) +
  theme_void()

metro_search_map

metro_BAME_map <- MSOA_shapes %>%
  st_join(metro_search_data, by = c("MSOA_code")) %>%
  rename(MSOA_code = MSOA_code.x) %>% 
  inner_join(MSOA_BAME_pop, by = c("MSOA_code")) %>%
  ggplot() +
  geom_sf(aes(fill = BAME_prop), alpha = 0.6) +
  scale_fill_viridis_c(name = str_wrap("BAME Percent of Population",width=15)) +
  theme_void()

metro_BAME_map
```

```{r}
#Regression analysis
MSOA_BAME_pop <- MSOA_BAME_pop %>% 
  inner_join(metro_search_data, by = c("MSOA_code")) %>% 
  as_tibble() %>% 
  mutate(percent_searches = (total_searches/sum(total_searches))*100)
reg1 <- lm(total_searches ~ BAME_prop, data = MSOA_BAME_pop)

tbl_regression(reg1)
```

## Appendix: All code in this assignment

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE} 
```



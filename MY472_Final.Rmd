---
title: "MY472_Final"
author: "CT-Dev1"
date: "01/01/2024"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r load_packages, eval = TRUE}
#Load required packages
library(ukpolice)
library(tidyverse)
library(sf)
library(sp)
library(httr)
library(jsonlite)
library(RSQLite)
library(httr)
library(netstat)
library(texreg)
library(gt)
#library(gtsummary)
```

```{r load_data, eval = TRUE}
#Ethnicity Population Data by LSOAs (downloaded from office for national statistics - 2021 data)
ethnicity_data <- read.csv("data\\LSOA_ethnicity.csv")

#Local District Shape Files from GeoJSON
LSOA_shapes <- st_read("data\\LSOA_shapefiles.geojson")

#Police Force Shape files from GeoJSON
pf_shapes <- st_read("data\\force_areas_shapefiles.geojson")
```

```{r clean_data, eval = TRUE}
#Create table for LSOAs by police force area
LSOA_by_force <- LSOA_shapes %>% 
  st_centroid() %>% 
  st_join(pf_shapes, join = st_intersects) %>% 
  as_tibble() %>%
  select(c(LSOA21CD, LSOA21NM, pfa16cd, pfa16nm)) %>% 
  rename(LSOA_code = LSOA21CD, LSOA_name = LSOA21NM, force_code = pfa16cd, force_name = pfa16nm)

#Create table for population by ethnicity for LSOA
ethnicity_by_LSOA <- ethnicity_data %>% 
  rename(LSOA_code = Lower.layer.Super.Output.Areas.Code, LSOA_name = Lower.layer.Super.Output.Areas, ethnic_group = Ethnic.group..20.categories.) %>%
  select(LSOA_code, Observation, ethnic_group) %>%
  pivot_wider(names_from = ethnic_group, values_from = Observation) %>% 
  mutate(total_pop = rowSums(across(where(is.numeric))))

#Joining the two tables
ethnicity_by_force <- LSOA_by_force %>% 
  full_join(ethnicity_by_LSOA, by = "LSOA_code") %>% 
  group_by(force_code, force_name) %>%
  mutate(force_name = str_replace_all(force_name, " Police", "")) %>%
  summarize(across(where(is.numeric), sum, na.rm = TRUE))

#Formatting force shape files to fit common coding
pf_shapes <- pf_shapes %>% 
  rename(force_name = pfa16nm) %>% 
  mutate(force_name = ifelse(force_name=="Metropolitan Police", "Metropolitan", force_name))

```

```{r get_ss_data, eval = TRUE}
#Create table that relates API input, force name and force code in standard format
police_forces <- ukc_forces()%>% 
  rename(force_name = name, ukc_input = id)%>% 
  mutate(force_name = str_replace_all(force_name, " Police", "")) %>% 
  mutate(force_name = str_replace_all(force_name, " Constabulary", "")) %>% 
  mutate(force_name = str_replace_all(force_name, "&", "and")) %>%
  mutate(force_name = str_replace_all(force_name, " Service", "")) %>%
  inner_join(ethnicity_by_force, by = "force_name") %>% 
  select(force_name, ukc_input, force_code)

#Vector of months to loop through, input into API
dates <- c("2022-01","2022-02","2022-03","2022-04","2022-05","2022-06","2022-07","2022-08","2022-09","2022-10","2022-11","2022-12")
```


```{r get_ss_data_2, eval = FALSE}
#Function to clean the raw data from API
clean_ss_data <- function(ss_data, force, month) {
  force_data <- ss_data %>% 
    mutate(ukc_input = force) %>% 
    inner_join(police_forces, by = "ukc_input") %>% 
    select(age_range, gender, self_defined_ethnicity, officer_defined_ethnicity, legislation, object_of_search, outcome_object_name, legislation, force_code, force_name, ukc_input) %>% 
    #replace "Not stated" ethnicity with NA
    mutate(self_defined_ethnicity = ifelse(grepl("Not stated", self_defined_ethnicity), NA, self_defined_ethnicity)) %>% 
    mutate(racial_group = ifelse(is.na(self_defined_ethnicity), officer_defined_ethnicity, self_defined_ethnicity)) %>% 
    #Add column for racial_group based on ethnicity classification
    mutate(racial_group = ifelse(grepl("White", racial_group, fixed = TRUE), 'White',
                           ifelse(grepl("Asian", racial_group, fixed = TRUE), 'Asian',
                           ifelse(grepl("Black", racial_group, fixed = TRUE), 'Black',
                           ifelse(grepl("Mixed", racial_group, fixed = TRUE), 'Mixed',
                           ifelse(grepl("Other", racial_group, fixed = TRUE), 'Other', NA)))))) %>% 
    mutate(month = month)
  return(force_data)
}

#Script to download stop and search data for all police forces over 2022

#Empty tibble to store the data
stop_search_2022 <- ukc_stop_search_force("bedfordshire","2022-01") %>%
  clean_ss_data("bedfordshire", "2022-01") %>%
  slice(0)

#table to store missing forces and months
missing_data = tibble(ukc_input = character(), month = character())
'
#Loop over all police forces and months
for (month in dates){
  for (force in police_forces$ukc_input){
    force_data <- ukc_stop_search_force(force, month)
    if (length(force_data)==0 | is.null(force_data)){
      missing_data <- missing_data %>% 
        add_row(ukc_input = force, month = month)
      next
    } else {
    stop_search_2022 <- force_data %>% 
      clean_ss_data(force, month) %>%
      rbind(stop_search_2022)
    }}
  Sys.sleep(3) 
}
'
```


```{r partial_missing_data_fill, eval = FALSE}
#There is missing data, so investigate police API issue log at https://data.police.uk/changelog/
#Some forces have partial missing data for 2022, so we will utilize forward propagation to fill in the data
'
#Create table of partial missing data
partial_missing_forces <- missing_data %>% 
  filter(ukc_input %in% c("greater-manchester","gwent", "north-yorkshire")==FALSE) %>% 
  mutate(month_index = as.numeric(str_replace_all(month, "2022-", ""))) 

#create table of inputs for forward propagation
forward_prop_input <- missing_data %>% 
  filter(ukc_input %in% c("greater-manchester","gwent", "north-yorkshire")==FALSE) %>% 
  group_by(ukc_input) %>%
  summarize(missing_months = n()) %>% 
  inner_join(police_forces, by = "ukc_input")

#Script to loop over missing data by force and month

for (force in forward_prop_input$ukc_input){
  missing_months <- forward_prop_input$missing_months[forward_prop_input$ukc_input==force]
  last_record_month <- min(partial_missing_forces$month_index[partial_missing_forces$ukc_input==force]) -1
  month_input <- paste0("2022-", last_record_month)
  for (i in 1:forward_prop_input$missing_months[forward_prop_input$ukc_input==force]){
    force_data <- ukc_stop_search_force(force, month_input)
    month_filled_input <- paste0("2022-", last_record_month+i)
    stop_search_2022 <- force_data %>% 
      clean_ss_data(force, month_filled_input) %>%
      rbind(stop_search_2022)
  }
}

#Write to disk, this is commented out, data is stored in stop_search_2022.csv in data folder (within the github)
#write_csv(stop_search_2022, "stop_search_2022.csv")


#test that forward filling worked using the test case of South Wales, which previously had some missing data

stop_search_2022 %>% 
  filter(force_name == "South Wales") %>% 
  group_by(month) %>% 
  summarize(total_stops = n()) %>% 
  print()

#Demonstration that API fails for some forces - greater manchester, gwent and north yorkshire
url <- "https://data.police.uk/api/stops-force?force=greater-manchester&date=2022-02"
json <- content(GET(url), "parsed")
print(is.null(json)|length(json)==0)
'
```

```{r load_ss_data, eval = TRUE}
#Load full dataset from csv
stop_search_2022 <- read_csv("data//stop_search_2022.csv")

#Manchester, Gwent and North Yorkshire have no data at all
#Rather than exclude from analysis, we can load in existing racial search data from gov.uk
missing_forces_ss <- read.csv("data/missing_forces_stop_search.csv")
missing_forces_ss <- missing_forces_ss %>% 
  rename(number_of_stop_and_searches_ethnicity_reported = total_number_of_stop_and_search_carried_out_in_this_year_in_this_area_excluding_cases_where_the_ethnicity_was_unreported, stop_search_rate_ethnicity = proportion_of_total_stop_and_searches_of_this_ethnicity_in_the_financial_year_excludes_unreported, force_name = geography) %>%
  mutate(time = as.character(time)) %>% 
  filter(force_name %in% c("Gwent", "Greater Manchester", "North Yorkshire")==TRUE) %>% 
  filter(geography_type == "Police Force Area" & time == "2021/22") %>% 
  #Note ethnicity column is coded differently in this dataset, includes labels for ethnicity and race
  select(ethnicity, force_name, number_of_stop_and_searches, number_of_stop_and_searches_ethnicity_reported, population_by_ethnicity, rate_per_1_000_population_by_ethnicity, stop_search_rate_ethnicity)

#Now we can combine these datasets to have a complete picture across all force areas

```

Notes on missing data source:
- Is for financial year 2021-22, so not exactly calendar year but a good approximation

```{r ss_by_race_tables, eval = TRUE}
#Begin by analyzing race

#To find search rate per 1000, first we need populations by force area
race_by_force <- ethnicity_by_force %>% 
  pivot_longer(cols = -c(force_code,force_name), names_to = "racial_group", values_to = "population") %>% 
  mutate(racial_group = ifelse(grepl("White", racial_group, fixed = TRUE), 'White',
                       ifelse(grepl("Asian", racial_group, fixed = TRUE), 'Asian',
                       ifelse(grepl("Black", racial_group, fixed = TRUE), 'Black',
                       ifelse(grepl("Mixed", racial_group, fixed = TRUE), 'Mixed',
                       ifelse(grepl("Other", racial_group, fixed = TRUE), 'Other', NA)))))) %>%
  group_by(force_name, racial_group) %>% 
  summarize(population = sum(population[racial_group==racial_group])) %>% 
  filter(is.na(racial_group)==FALSE) %>%
  pivot_wider(names_from = racial_group, values_from = "population", names_prefix = "population_") %>% 
  mutate(population_Total = population_White + population_Black + population_Mixed + population_Asian + population_Other) %>%
  inner_join(police_forces, by = "force_name")

#First let's find the number of stops by race for the three missing forces (Manchester, Gwent and North Yorkshire)
race_stops_data_missing <- missing_forces_ss %>% 
  filter(ethnicity %in% c("White", "Black", "Mixed", "Asian", "Other")==TRUE) %>% 
  select(c(number_of_stop_and_searches, ethnicity, force_name)) %>% 
  pivot_wider(names_from = ethnicity, values_from = number_of_stop_and_searches, names_prefix = "stops_")

#Next lets find the total searches by force area, including those with no racial data
stops_total_by_force <- stop_search_2022 %>% 
  group_by(force_name) %>% 
  summarize(number_of_stop_and_searches = n()) %>% 
  inner_join(police_forces, by = "force_name") %>% 
  bind_rows(missing_forces_ss) %>% 
  #get first 43 rows
  slice(1:43) %>%
  select(force_name, number_of_stop_and_searches) %>%
  rename(stops_Total = number_of_stop_and_searches)

#Finally, lets aggregate all tables, finding racial stop rates for each force - FINAL RACIAL DATA
race_stops_data <- stop_search_2022 %>% 
  #Filter for stops where racial group is known
  filter(is.na(racial_group)==FALSE) %>% 
  group_by(force_name) %>% 
  summarize(stops_Black = sum(racial_group=="Black"), stops_White = sum(racial_group=="White"), stops_Mixed = sum(racial_group=="Mixed"), stops_Asian = sum(racial_group=="Asian"), stops_Other = sum(racial_group=="Other")) %>% 
  #Add the missing forces
  rbind(race_stops_data_missing) %>%
  mutate(stops_All = stops_Black + stops_White + stops_Mixed + stops_Asian + stops_Other) %>%
  inner_join(police_forces, by = "force_name") %>%
  inner_join(race_by_force, by = c("force_name","force_code","ukc_input")) %>%
  #Find rates of stop and search per 1000 people
  inner_join(stops_total_by_force, by = "force_name") %>% 
  mutate(stop_rate_black = (stops_Black/population_Black)*1000, stop_rate_white = (stops_White/population_White)*1000, stop_rate_mixed = (stops_Mixed/population_Mixed)*1000, stop_rate_asian = (stops_Asian/population_Asian)*1000, stop_rate_other = (stops_Other/population_Other)*1000, stop_rate_all_races = (stops_All/population_Total)*1000, stops_rate_Total = (stops_Total/population_Total)*1000) 
```

-note that the rate is based on the number of stops where ethnicity is reported, this can change the rate significantly
- in the above, the total stop and searches are those with no ethnicity reported

```{r visualize_total_ss_rate, eval=TRUE}
#We can visualize the above table on a map to get a better sense of geographic variation

total_stop_rate_map <- pf_shapes %>% 
  inner_join(race_stops_data, by = c("force_name")) %>%
  select(force_name, stops_rate_Total) %>%
  #Filter out city of london as outlier
  filter(force_name != "City of London") %>%
  ggplot(aes(fill = stops_rate_Total)) + geom_sf() +
  scale_fill_viridis_c(option = "plasma", direction = -1, na.value = "grey90", name = "Total searches per 1000 residents") +
  theme_void() +
  theme(legend.position = "bottom") +
  labs(title = "Stop and Search Rate by Police Force Area", subtitle = "2022", caption = "Source: police.uk | Based on Total Searches Conducted")

total_stop_rate_map
```
-Exclude city of london from further estimates


```{r visualize_total_ss_rate, eval=TRUE}
#Now we can visualize the racial search data

#Summary table - race stop rates by force
race_stops_data %>% 
  select(force_name, stop_rate_black, stop_rate_white, stop_rate_mixed, stop_rate_asian, stop_rate_other, stop_rate_all_races, stops_rate_Total) %>%
  rename("Police Force" = force_name, Black = stop_rate_black, White = stop_rate_white, Mixed = stop_rate_mixed, Asian = stop_rate_asian, Other = stop_rate_other, "All Races*" = stop_rate_all_races, "Total Stops**" = stops_rate_Total) %>%
  gt() %>% 
  fmt_number(columns = c(everything()), decimals = 2) %>%
  tab_header(title = md("**Rates of Stop and Search by Racial Group and Police Force Area**")) %>% tab_spanner(label = md("**Rate per 1000 Residents in 2022**"), columns = c(2:8)) %>% 
  opt_row_striping() %>% 
  tab_footnote(
    footnote = "
    *'All Races' is the rate for all stops where racial data is recorded | **'Total stops' is the rate for all stops recorded"
  ) %>% 
  tab_style(
    style = list(cell_text(weight = "bold")),
    locations = list(cells_column_labels(columns = everything()), cells_body(columns = c(1))))
```
FORMAT PAPER --> https://www.ethnicity-facts-figures.service.gov.uk/crime-justice-and-the-law/policing/stop-and-search/latest/


Notes on table above:
- Demonstrates stop and search rate varies significantly across areas
- Gives the outlier of City of London - it should be removed from further analysis
- Note that all races stop rate may be smaller than official statistics given that we are analysing on searches where race is known
- add column for demographic - number of total searches and population


```{r visualize_black_ss_rate, eval=TRUE}
library(viridis)
black_stop_rate_map <- pf_shapes %>% 
  inner_join(race_stops_data, by = c("force_name")) %>%
  select(force_name, stop_rate_black, stop_rate_white) %>% 
  mutate(black_white_ratio = stop_rate_black/stop_rate_white) %>%
  #black_white_ratio defaults to 5 when above 5 for the graphical representation
  #mutate(black_white_ratio = ifelse(black_white_ratio > 5, 5, black_white_ratio)) %>%
  mutate(black_white_ratio = log(black_white_ratio)) %>%
  filter(force_name != "City of London") %>%
  ggplot(aes(fill = black_white_ratio)) + 
  geom_sf() +
  scale_fill_viridis_c(
    option = "plasma", 
    direction = -1, 
    na.value = "red", 
    name = "Log Likelihood of Stop-and-Search for Black vs. White",
    trans = "identity",
    limits = c(0, 3),
    breaks = c(0, 1, 2, 3) 
  ) +
  theme_void() +
  theme(legend.position = "bottom") +
  labs(title = "Difference in Search Rates by Force Area: Black vs. White", subtitle = "2022", caption = "Source: police.uk | Based on Total Stops Conducted | Log Likelihood of 0 represents 1:1 chance of being stopped")
black_stop_rate_map
```
- Fix the above map caption etc. - CENTRE THE TITLE
- Change the above to have a logarithmic scale instead of log variable


Now to address some summary statistics
```{r}
#Statistics on stop rate
stats_ss_table <- stop_search_2022 %>% 
  summarize(
    total_stops = n(),
    
  )


#




```





```{r}
#Ethnicity analysis data set



```





Now, to run some statistical tests using linear regression
```{r regression_full_data, eval=TRUE}
#Table of stops by race by force, tidy long format
race_stops_data_long <- race_stops_data %>% 
  select(stop_rate_black, stop_rate_white, stop_rate_mixed, stop_rate_asian, stop_rate_other, force_name) %>%
  rename(Black = stop_rate_black, White = stop_rate_white, Mixed = stop_rate_mixed, Asian = stop_rate_asian, Other = stop_rate_other) %>%
  pivot_longer(cols = c(Black, White, Mixed, Asian, Other), names_to = "racial_group", values_to = "stops_rate_per_1000") %>% print()

#Data for regression - on searches in stop_search_2022, ie. not including the missing forces
regression_data <- stop_search_2022 %>% 
  filter(is.na(racial_group)==FALSE) %>%
  inner_join(race_stops_data_long, by = c("racial_group","force_name")) %>% 
  filter(force_name != "City of London") %>%
  mutate(racial_group = as_factor(racial_group), force_name = as_factor(force_name)) %>% 
  rename(Male = gender) %>% 
  mutate(Male = ifelse(Male == "Male", 1, 0)) 


#Multiple Linear Regression model, finding effect of race, force area, male gender on likelihood of being stopped 
#set the reference groups to be white for racial group and Kent for force area, as it has near-average stop and search rate (6.78 per 1000)
reg1 <- lm(stops_rate_per_1000 ~ relevel(racial_group, ref="White") + relevel(force_name, ref="Kent") + Male, data = regression_data)

#Tidy Present
screenreg(reg1)
```




```{r}
#Number of searches by ethnicity by force
ethnicity_stops <- stop_search_2022 %>% 
    mutate(self_defined_ethnicity = ifelse(grepl("Not stated", self_defined_ethnicity), NA, self_defined_ethnicity)) %>% 
    filter(is.na(self_defined_ethnicity)==FALSE) %>% 
    group_by(self_defined_ethnicity, force_name) %>% 
    summarize(total_stops = n()) %>% 
    pivot_wider(names_from = self_defined_ethnicity, values_from = total_stops)


harmonize_ethnicity <- function(ethnicity) {
  # Define the mapping between census and police ethnicities
  mapping <- list(
    "Asian, Asian British or Asian Welsh: Other Asian" = "Asian/Asian British - Any other Asian background",
    "White: English, Welsh, Scottish, Northern Irish or British" = "White - English/Welsh/Scottish/Northern Irish/British",
    "Does not apply" = NA,
    "Mixed or Multiple ethnic groups: Other Mixed or Multiple ethnic groups" = "Mixed/Multiple ethnic groups - Any other Mixed/Multiple ethnic background",
    "White: Other White" = "White - Any other White background",
    "Black, Black British, Black Welsh, Caribbean or African: African" = "Black/African/Caribbean/Black British - African",
    "Black, Black British, Black Welsh, Caribbean or African: Other Black" = "Black/African/Caribbean/Black British - Any other Black/African/Caribbean background",
    "Asian, Asian British or Asian Welsh: Pakistani" = "Asian/Asian British - Pakistani",
    "Asian, Asian British or Asian Welsh: Bangladeshi" = "Asian/Asian British - Bangladeshi",
    "Other ethnic group: Any other ethnic group" = "Other ethnic group - Any other ethnic group",
    "Mixed or Multiple ethnic groups: White and Black African" = "Mixed/Multiple ethnic groups - White and Black African",
    "White: Gypsy or Irish Traveller" = "White - Gypsy or Irish Traveller",
    "Mixed or Multiple ethnic groups: White and Black Caribbean" = "Mixed/Multiple ethnic groups - White and Black Caribbean",
    "Other ethnic group: Arab" = "Other ethnic group - Arab",
    "White: Irish" = "White - Irish",
    "Black, Black British, Black Welsh, Caribbean or African: Caribbean" = "Black/African/Caribbean/Black British - Caribbean",
    "Mixed or Multiple ethnic groups: White and Asian" = "Mixed/Multiple ethnic groups - White and Asian",
    "Asian, Asian British or Asian Welsh: Indian" = "Asian/Asian British - Indian",
    "Asian, Asian British or Asian Welsh: Chinese" = "Asian/Asian British - Chinese"
  )
  # Return the corresponding police ethnicity, or NA if no match is found
  return(ifelse(ethnicity %in% names(mapping), mapping[[ethnicity]], NA))
}

ethnicity_by_force_harmonized <- ethnicity_by_force %>% 
  pivot_longer(names_to = "ethnicity", values_to = "total_stops",cols= -c(force_code,force_name))

#ENCOUNTERS ERROR WITH THE ABOVE


#rate per 1000 population by ethnicity by force
ethnicity_stop_rates <- ethnicity_stops %>% 
  

inner_join(ethnicity_by_force, by = "force_name") %>%
  print()
  
```


```{r}
#number of searches by ethnicity
  ss_analysis_ethnicity <- force_data %>% 
    select(age_range, gender, self_defined_ethnicity, officer_defined_ethnicity, legislation, object_of_search, outcome_object_name, legislation) %>%
    mutate(self_defined_ethnicity = ifelse(grepl("Not stated", self_defined_ethnicity), NA, self_defined_ethnicity)) %>% 
    filter(is.na(self_defined_ethnicity)==FALSE) %>% 
    group_by(self_defined_ethnicity) %>% 
    summarize(total_stops = n(), male_stops = sum(grepl("Male",gender)), female_stops = sum(grepl("Female",gender)))
  
  #full population analysis
  ss_analysis_total_pop <- force_data %>% 
    select(age_range, gender, self_defined_ethnicity, officer_defined_ethnicity, legislation, object_of_search, outcome_object_name, legislation) %>%
    summarize(total_stops = n(), male_stops = sum(grepl("Male",gender)), female_stops = sum(grepl("Female",gender)))
  
  #join into larger table
  ss_data <- ethnicity_by_force %>% 
    full_join()
  
}
  

```


To think about:
- Writing to database
- Get database on all stop and search data for time period for each police force 
- Then you can query it to get all the relevant statistics
- Instead of using crime statistics to determine if there is bias, you can look at the rate of arrest by stop and search


Notes on above:
- You'll have to replace the path with a path online - replicable - however all the data sources are the best available
- Remember to change the above ethnicity_data path to an original data source - its currently on the data you've pre-edited
- add in age data later on


Notes on above:
- If you have time, rename all the variables to be consistent across all dataframes
- Reference the fact that you tested the level of distortion so that it is not too extreme
- If you have time, put all the data frames into a SQL database and query it for analyses where local district code is the primary key



```{r}

#find all the different ethnicity types in the stop search data
metro_force_data <- ukc_stop_search_force("metropolitan", "2021-06")
ethnicity_bins <- unique(metro_force_data$self_defined_ethnicity)
ethnicity_bins[is.na(ethnicity_bins)] <- "NA" #string representation of NA

#Creating a dictionary of ethnicity types
#Represents the 18 ethnicity bins used in the stop_search data
ethnicity_dict <- c("NA" = "NA", "Other ethnic group - Not stated" = "NA", 
                    "Black/African/Caribbean/Black British - African" = "black_african", 
                    "Asian/Asian British - Pakistani" = "asian_pakistani", 
                    "White - Any other White background" = "white_other", 
                    "Asian/Asian British - Any other Asian background" = "asian_other", 
                    "White - English/Welsh/Scottish/Northern Irish/British" = "white_british", 
                    "Black/African/Caribbean/Black British - Any other Black/African/Caribbean background" = "black_other", 
                    "Mixed/Multiple ethnic groups - White and Black Caribbean" = "mixed_white_black_caribbean", 
                    "Other ethnic group - Any other ethnic group" = "other", 
                    "Asian/Asian British - Indian" = "asian_indian", 
                    "Mixed/Multiple ethnic groups - Any other Mixed/Multiple ethnic background" = "mixed_other", 
                    "Black/African/Caribbean/Black British - Caribbean" = "black_carribean", 
                    "Asian/Asian British - Chinese" = "asian_chinese", 
                    "White - Irish" = "white_irish", 
                    "Mixed/Multiple ethnic groups - White and Black African" = "mixed_white_black_african", 
                    "Mixed/Multiple ethnic groups - White and Asian" = "mixed_white_asian", 
                    "Asian/Asian British - Bangladeshi" = "asian_bangladeshi")

#Constructing the data frames to store results by district
NA_data_by_district_ethnicity <- as.tibble(data.frame(district_code = local_districts$LAD22CD, district_name = local_districts$LAD22NM))
ss_by_district_race <- as.tibble(data.frame(district_code = local_districts$LAD22CD, district_name = local_districts$LAD22NM, total_stops = NA, stops_White = NA, stops_Asian = NA, stops_Black = NA, stops_Mixed = NA, stops_Other = NA))
#ethnicity data by district
ss_by_district_ethnicity <- as.tibble(data.frame(district_code = local_districts$LAD22CD, district_name = local_districts$LAD22NM))
na_matrix <- matrix(NA, ncol = length(ethnicity_bins), nrow = 331)
colnames(na_matrix) <- ethnicity_bins
ss_by_district_ethnicity <- cbind(ss_by_district_ethnicity, na_matrix)
                                      
#BUILDING FUNCTION TO AGGREGATE THE DATA by LOCAL DISTRICT - STARTING WITH STOP-SEARCH RATES
district_data <- ukc_stop_search_poly(local_districts[309,], "2021-06")

#error handling
if (is.null(district_data)) {
  print("here")
} else {
    print("there")
  }

#
NA_responses <- district_data %>%
  #replace self defined ethnicity which is 'ethnicity not stated' as NA
  mutate(self_defined_ethnicity = ifelse(grepl("Not stated", self_defined_ethnicity, fixed = TRUE), NA, self_defined_ethnicity)) %>% 
  #filter for the rows with no racial/ethnicity data whatsoever
  filter(is.na(self_defined_ethnicity) & is.na(officer_defined_ethnicity)) %>%
  #create new column that defaults to self_defined_ethnicity unless is NA, then officer defined ethnicity
  mutate(race = ifelse(is.na(self_defined_ethnicity), officer_defined_ethnicity, self_defined_ethnicity)) %>%
  summarize(stops_w_missing_ethnicity = sum(is.na(race))) %>% 
  mutate(district_code = local_districts[309,]$LAD22CD, district_name = local_districts[309,]$LAD22NM) %>%  #FORMAT LATER SO IT JUST REFERS TO THE DISTRICT BEING ITERATED OVER
  print()

#Add Na_responses to the NA_data_by_district_ethnicity data frame
full_join(NA_data_by_district_ethnicity, NA_responses, by= "district_code") %>% print()


district_ethnicity_data <- district_data %>% 
  #remove rows with no ethnicity data
  filter(is.na(self_defined_ethnicity)==FALSE | is.na(officer_defined_ethnicity)==FALSE) %>%
  #replace self defined ethnicity which is 'ethnicity not stated' as NA
  mutate(self_defined_ethnicity = ifelse(grepl("Not stated", NA, self_defined_ethnicity))) %>% 
  #create new column that defaults to self_defined_ethnicity unless is NA, then officer defined ethnicity
  mutate(ethnicity = ifelse(is.na(self_defined_ethnicity), officer_defined_ethnicity, self_defined_ethnicity)) %>% 
  #Classify each search as its umbrella ethnicity group (ie. race)
  mutate(umbrella_ethnicity = ifelse(grepl("White", ethnicity, fixed = TRUE), 'White',
                             ifelse(grepl("Asian", ethnicity, fixed = TRUE), 'Asian',
                             ifelse(grepl("Black", ethnicity, fixed = TRUE), 'Black',
                             ifelse(grepl("Mixed", ethnicity, fixed = TRUE), 'Mixed',
                             ifelse(grepl("Other", ethnicity, fixed = TRUE), 'Other', NA)))))) %>% 
  #summarize the data
  #count the number of instances of each ethnic umbrella group
  group_by(umbrella_ethnicity) %>% 
  #sum the number of each ethnicity
  tally() %>% print()
  
  
  
district_ethnicity_data <- district_data %>% 
  filter(is.na(self_defined_ethnicity)==FALSE | is.na(officer_defined_ethnicity)==FALSE) %>%
  #create new column that defaults to self_defined_ethnicity, else officer defined ethnicity
  mutate(ethnicity = ifelse(is.na(self_defined_ethnicity), officer_defined_ethnicity, self_defined_ethnicity)) %>% 
  #Add an ethnic umbrella group indicator
  mutate(umbrella_ethnicity = ifelse(grepl("White", ethnicity, fixed = TRUE), 'White',
                                     ifelse(grepl("Asian", ethnicity, fixed = TRUE), 'Asian',
                                     ifelse(grepl("Black", ethnicity, fixed = TRUE), 'Black',
                                     ifelse(grepl("Mixed", ethnicity, fixed = TRUE), 'Mixed',
                                     ifelse(grepl("Other", ethnicity, fixed = TRUE), 'Other', NA)))))) %>% 
  #summarize the data
  #count the number of instances of each ethnic umbrella group
  group_by(self_defined_ethnicity) %>% 
  #sum the number of each ethnicity
  tally() %>% print()
  




```
Notes on above:
- IF you want to summarize the individual ethnic bins then you can just add more to the mutate ifelse batch
- Note that if there are no ethnicity matches to the categories, it outputs an NA
- you need to add handling for the not-stated category in the data
- What if we include the mixed race people within their most visible racial category? (ie. black, white, asian, other)

Incongruencies (thigns in census data not in stop_search data):
- Gypsy and Irish Traveller is not recorded as an option in the stop search ethnicity data
- White: Roma
- Any other ethnic background: Arab

Things included in stop_search data but not in census data:
- Other ethnic group: Not stated
- NA

Dealing with NA data:
- Clearly state the proportion of stop and search records with missing ethnicity data in each district
- Consider doing a sensitivity analysis - see how different approaches to handling NA data (including vs. excluding) affect your results
- Discuss Potential Implications of NA data, are there any patterns (certain districts, time periods)

Dealing with no location data:
- This obviously makes the use of poly shapes less reliable
- use a robustness check on the rates of stop/search within the ukc_stop_search no location function


```{r}
#NEXT STEPS

# 1) Aggregate the necessary crime, ethnicity data in batches so you never store a full dataframe with all the information that is being analyzed in total

# use the table in the folder on ethnicity statistics by local district area

```


```{r}
#Pass the shs files as arguments to the API

#ukc_stop_search_poly - see usage


```


Now to begin the data analysis

```{r}
#apply sf_simplify and st_transform to all the shape files
local_districts_simp <- st_transform(st_simplify(local_districts, dTolerance = 50), crs = 4326)

#create function that gets the monthly stop_search data for each local district

get_stop_search_by_month <- function(search_month){
  #create empty dataframe
  stop_search_df <- data.frame()
  #loop over all the local districts
  for (i in 1:nrow(local_districts_simp)){
    #pass to the API
    data <- ukc_stop_search_poly(local_districts_simp[i,],search_month)
    #append to the dataframe
    stop_search_df <- rbind(stop_search_df, data)
  }
  return(stop_search_df)
}

for (i in 1:nrow(local_districts_simp)){
  #convert to latlong
  local_districts_simp_latlong <- st_transform(local_districts_simp, crs = 4326)
  #pass to the API
  data <- ukc_stop_search_poly(local_districts_simp_latlong[i,],"2022-01")
  #save the data
  save(data, file = paste0("C:\\Users\\rhrou\\OneDrive\\Desktop\\ASDS\\MY472\\MY472-Final\\usable_data\\",local_districts_simp_latlong$LAD22NM[i],".RData"))
}



```




```{r}
age_gender_data <- read.csv("C:\\Users\\rhrou\\OneDrive\\Desktop\\ASDS\\MY472\\MY472-Final\\usable_data\\local_district_population_age_gender.csv")

age_gender_districts <- unique(age_gender_data$Lower.tier.local.authorities.Code)

ethnicity_data <- read.csv("C:\\Users\\rhrou\\OneDrive\\Desktop\\ASDS\\MY472\\MY472-Final\\usable_data\\ethnicity_data_pop_numbers.csv")

ethnicity_districts <- unique(ethnicity_data$Area.code)

shape_file_districts <- unique(local_districts$LAD22CD)

#find the districts in age_gender_districts not in ethnicity_districts

print(sum(shape_file_districts %in% ethnicity_districts == FALSE))

print(local_districts$LAD22CD[local_districts$LAD22CD %in% age_gender_districts == FALSE])

local_districts$LAD22CD %in% age_gender_districts

print(sum(is.na(age_gender_data$Lower.tier.local.authorities.Code)))


#remove all rows from local_districts which are not in age_gender_districts

local_districts_test <- local_districts[local_districts$LAD22CD %in% unique(age_gender_data$Lower.tier.local.authorities.Code),]





ukc_stop_search_poly(local_districts_simp[286,],"2022-06")


local_districts_simp[2,]$LAD22NM



```



